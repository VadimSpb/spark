{"paragraphs":[{"title":"Задание 1","text":"%md\n\n\n\nДля упражнений сгрененирован большой набор синтетических данных в таблице `hw2.events_full`. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера `kotelnikov.sample_[small, big, very_big]`. \n\nОтветить на вопросы:\n * какова структура таблиц\n * сколько в них записей \n * сколько места занимают данные\n ","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:41:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Для упражнений сгрененирован большой набор синтетических данных в таблице <code>hw2.events_full</code>. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера <code>kotelnikov.sample_[small, big, very_big]</code>.</p>\n<p>Ответить на вопросы:</p>\n<ul>\n<li>какова структура таблиц</li>\n<li>сколько в них записей</li>\n<li>сколько места занимают данные</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1608697987532_-1642649736","id":"20201128-094640_2955666","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T18:41:20+0000","dateFinished":"2020-12-25T18:41:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3483"},{"text":"%pyspark\n\nevents_full = spark.table(\"hw2.events_full\")\nsample = spark.table(\"hw2.sample\")\nsample_small = spark.table(\"hw2.sample_small\")\nsample_big = spark.table(\"hw2.sample_big\")\nsample_very_big = spark.table(\"hw2.sample_very_big\")\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:50:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1608919866659_692627373","id":"20201225-181106_9805389","dateCreated":"2020-12-25T18:11:06+0000","dateStarted":"2020-12-25T19:50:49+0000","dateFinished":"2020-12-25T19:51:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3484"},{"text":"%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample\\\"\")\n\nprint(\"Schema:\")\nsample.printSchema()\n\nprint(\"Rows count:\")\nprint(sample.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample\")\\\n    .filter(col(\"col_name\") == \"Statistics\")\\\n    .show()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:30:07+0000","config":{"colWidth":3,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Table \"sample\"\nSchema:\nroot\n |-- event_id: string (nullable = true)\n\nRows count:\n104592\n\nData size:\n+----------+-------------+-------+\n|  col_name|    data_type|comment|\n+----------+-------------+-------+\n|Statistics|6663726 bytes|       |\n+----------+-------------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1608919893250_1727869571","id":"20201225-181133_2029278045","dateCreated":"2020-12-25T18:11:33+0000","dateStarted":"2020-12-25T18:30:07+0000","dateFinished":"2020-12-25T18:30:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3485"},{"text":"%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample_small\\\"\")\n\nprint(\"Schema:\")\nsample_small.printSchema()\n\nprint(\"Rows count:\")\nprint(sample_small.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample_small COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample_small\")\\\n    .filter(col(\"col_name\") == \"Statistics\")\\\n    .show()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:31:15+0000","config":{"colWidth":3,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Table \"sample_small\"\nSchema:\nroot\n |-- event_id: string (nullable = true)\n\nRows count:\n100\n\nData size:\n+----------+----------+-------+\n|  col_name| data_type|comment|\n+----------+----------+-------+\n|Statistics|7247 bytes|       |\n+----------+----------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1608919896197_1995823822","id":"20201225-181136_583820608","dateCreated":"2020-12-25T18:11:36+0000","dateStarted":"2020-12-25T18:31:15+0000","dateFinished":"2020-12-25T18:31:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3486"},{"text":"%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample_big\\\"\")\n\nprint(\"Schema:\")\nsample_big.printSchema()\n\nprint(\"Rows count:\")\nprint(sample_big.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample_big COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample_big\")\\\n    .filter(col(\"col_name\") == \"Statistics\")\\\n    .show()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:31:17+0000","config":{"colWidth":3,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Table \"sample_big\"\nSchema:\nroot\n |-- event_id: string (nullable = true)\n\nRows count:\n449166\n\nData size:\n+----------+--------------+-------+\n|  col_name|     data_type|comment|\n+----------+--------------+-------+\n|Statistics|28608600 bytes|       |\n+----------+--------------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1608919899711_-1425603158","id":"20201225-181139_1736773705","dateCreated":"2020-12-25T18:11:39+0000","dateStarted":"2020-12-25T18:31:18+0000","dateFinished":"2020-12-25T18:31:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3487"},{"text":"%pyspark\nfrom pyspark.sql.functions import col\n\nprint(\"Table \\\"sample_very_big\\\"\")\n\nprint(\"Schema:\")\nsample_very_big.printSchema()\n\nprint(\"Rows count:\")\nprint(sample_very_big.count())\n\nprint(\"\\nData size:\")\nspark.sql(\"ANALYZE TABLE hw2.sample_very_big COMPUTE STATISTICS NOSCAN\")\nspark\\\n    .sql(\"DESCRIBE EXTENDED hw2.sample_very_big\")\\\n    .filter(col(\"col_name\") == \"Statistics\")\\\n    .show()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:31:20+0000","config":{"colWidth":3,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Table \"sample_very_big\"\nSchema:\nroot\n |-- event_id: string (nullable = true)\n\nRows count:\n2248079\n\nData size:\n+----------+---------------+-------+\n|  col_name|      data_type|comment|\n+----------+---------------+-------+\n|Statistics|143186369 bytes|       |\n+----------+---------------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1608919933325_1887030750","id":"20201225-181213_862150484","dateCreated":"2020-12-25T18:12:13+0000","dateStarted":"2020-12-25T18:31:20+0000","dateFinished":"2020-12-25T18:31:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3488"},{"title":"Задание 2","text":"%md\nПолучить планы запросов для джойна большой таблицы `hw2.events_full` с каждой из таблиц `hw2.sample`, `hw2.sample_big`, `hw2.sample_very_big` по полю `event_id`. \nВ каких случаях используется **BroadcastHashJoin**? \n\n**BroadcastHashJoin** автоматически выполняется для джойна с таблицами, размером меньше параметра `spark.sql.autoBroadcastJoinThreshold`. \nУзнать его значение можно командой `spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")`.","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:47:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Получить планы запросов для джойна большой таблицы <code>hw2.events_full</code> с каждой из таблиц <code>hw2.sample</code>, <code>hw2.sample_big</code>, <code>hw2.sample_very_big</code> по полю <code>event_id</code>.\n<br  />В каких случаях используется <strong>BroadcastHashJoin</strong>?</p>\n<p><strong>BroadcastHashJoin</strong> автоматически выполняется для джойна с таблицами, размером меньше параметра <code>spark.sql.autoBroadcastJoinThreshold</code>.\n<br  />Узнать его значение можно командой <code>spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1608697987533_2035655922","id":"20201128-132950_831220047","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T18:47:29+0000","dateFinished":"2020-12-25T18:47:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3489"},{"text":"%pyspark\nspark.conf.get('spark.sql.autoBroadcastJoinThreshold')","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:38:14+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"u'26214400'\n"}]},"apps":[],"jobName":"paragraph_1608788308263_381394544","id":"20201224-053828_1507947136","dateCreated":"2020-12-24T05:38:28+0000","dateStarted":"2020-12-25T18:38:15+0000","dateFinished":"2020-12-25T18:38:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3490"},{"text":"%pyspark\n\nevents_full.join(sample, \"event_id\").explain()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:56:58+0000","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(2) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n+- *(2) BroadcastHashJoin [event_id#1072], [event_id#0], Inner, BuildRight\n   :- *(2) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n   :  +- *(2) Filter isnotnull(event_id#1072)\n   :     +- *(2) FileScan parquet hw2.events_full[event_id#1072,city#1073,skew_key#1074,date#1075] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string,city:string,skew_key:string>\n   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n      +- *(1) Project [event_id#0]\n         +- *(1) Filter isnotnull(event_id#0)\n            +- *(1) FileScan parquet hw2.sample[event_id#0] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sample], PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"}]},"apps":[],"jobName":"paragraph_1608921733390_144358161","id":"20201225-184213_106370609","dateCreated":"2020-12-25T18:42:13+0000","dateStarted":"2020-12-25T18:56:58+0000","dateFinished":"2020-12-25T18:56:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3491"},{"text":"%pyspark\n\nevents_full.join(sample_small, \"event_id\").explain()\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:57:27+0000","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(2) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n+- *(2) BroadcastHashJoin [event_id#1072], [event_id#2], Inner, BuildRight\n   :- *(2) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n   :  +- *(2) Filter isnotnull(event_id#1072)\n   :     +- *(2) FileScan parquet hw2.events_full[event_id#1072,city#1073,skew_key#1074,date#1075] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string,city:string,skew_key:string>\n   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n      +- *(1) Project [event_id#2]\n         +- *(1) Filter isnotnull(event_id#2)\n            +- *(1) FileScan parquet hw2.sample_small[event_id#2] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"}]},"apps":[],"jobName":"paragraph_1608921818163_-678993269","id":"20201225-184338_1082207107","dateCreated":"2020-12-25T18:43:38+0000","dateStarted":"2020-12-25T18:57:27+0000","dateFinished":"2020-12-25T18:57:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3492"},{"text":"%pyspark\nevents_full.join(sample_big, \"event_id\").explain()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:58:17+0000","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(5) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n+- *(5) SortMergeJoin [event_id#1072], [event_id#4], Inner\n   :- *(2) Sort [event_id#1072 ASC NULLS FIRST], false, 0\n   :  +- Exchange hashpartitioning(event_id#1072, 200)\n   :     +- *(1) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n   :        +- *(1) Filter isnotnull(event_id#1072)\n   :           +- *(1) FileScan parquet hw2.events_full[event_id#1072,city#1073,skew_key#1074,date#1075] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string,city:string,skew_key:string>\n   +- *(4) Sort [event_id#4 ASC NULLS FIRST], false, 0\n      +- Exchange hashpartitioning(event_id#4, 200)\n         +- *(3) Project [event_id#4]\n            +- *(3) Filter isnotnull(event_id#4)\n               +- *(3) FileScan parquet hw2.sample_big[event_id#4] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"}]},"apps":[],"jobName":"paragraph_1608921884400_1235434583","id":"20201225-184444_1482438089","dateCreated":"2020-12-25T18:44:44+0000","dateStarted":"2020-12-25T18:58:17+0000","dateFinished":"2020-12-25T18:58:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3493"},{"text":"%pyspark\nevents_full.join(sample_very_big, \"event_id\").explain()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:58:19+0000","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(5) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n+- *(5) SortMergeJoin [event_id#1072], [event_id#6], Inner\n   :- *(2) Sort [event_id#1072 ASC NULLS FIRST], false, 0\n   :  +- Exchange hashpartitioning(event_id#1072, 200)\n   :     +- *(1) Project [event_id#1072, city#1073, skew_key#1074, date#1075]\n   :        +- *(1) Filter isnotnull(event_id#1072)\n   :           +- *(1) FileScan parquet hw2.events_full[event_id#1072,city#1073,skew_key#1074,date#1075] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 15, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string,city:string,skew_key:string>\n   +- *(4) Sort [event_id#6 ASC NULLS FIRST], false, 0\n      +- Exchange hashpartitioning(event_id#6, 200)\n         +- *(3) Project [event_id#6]\n            +- *(3) Filter isnotnull(event_id#6)\n               +- *(3) FileScan parquet hw2.sample_very_big[event_id#6] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"}]},"apps":[],"jobName":"paragraph_1608921888187_945311443","id":"20201225-184448_981215659","dateCreated":"2020-12-25T18:44:48+0000","dateStarted":"2020-12-25T18:58:19+0000","dateFinished":"2020-12-25T18:58:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3494"},{"title":"Задание 3","text":"%md\nВыполнить джойны с таблицами  `hw2.sample`,  `hw2.sample_big` в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать `.count()` для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении\n\nЗайти в spark ui (ссылку сгенерировать в следующем папраграфе). Сколько tasks создано на каждую операцию? Почему именно столько? Каков DAG вычислений?  ","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:58:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Выполнить джойны с таблицами  <code>hw2.sample</code>,  <code>hw2.sample_big</code> в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать <code>.count()</code> для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении</p>\n<p>Зайти в spark ui (ссылку сгенерировать в следующем папраграфе). Сколько tasks создано на каждую операцию? Почему именно столько? Каков DAG вычислений?</p>\n"}]},"apps":[],"jobName":"paragraph_1608697987534_-1355475960","id":"20201128-140231_1065047171","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T18:58:27+0000","dateFinished":"2020-12-25T18:58:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3495"},{"text":"%pyspark\n\nevents_full.join(sample, \"event_id\").count()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T18:58:59+0000","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"104592\n"}]},"apps":[],"jobName":"paragraph_1608922252558_-1345086609","id":"20201225-185052_2031100733","dateCreated":"2020-12-25T18:50:52+0000","dateStarted":"2020-12-25T18:51:14+0000","dateFinished":"2020-12-25T18:53:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3496"},{"text":"%pyspark\nevents_full.join(sample_big, \"event_id\").count()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:18:48+0000","config":{"colWidth":6,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Py4JJavaError: An error occurred while calling o332.count.\n: org.apache.spark.SparkException: Job 127 cancelled because killed via the Web UI\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:1575)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1568)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1568)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:234)\n\tat org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:1568)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1835)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2039)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2060)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2079)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2104)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2775)\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2774)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2774)\n\tat sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError(u'An error occurred while calling o332.count.\\n', JavaObject id=o333), <traceback object at 0x7f0a497f1fc8>)"}]},"apps":[],"jobName":"paragraph_1608922334152_721603909","id":"20201225-185214_1867346605","dateCreated":"2020-12-25T18:52:14+0000","dateStarted":"2020-12-25T19:18:48+0000","dateFinished":"2020-12-25T19:29:22+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:3497"},{"title":"Генерация ссылки на  spark UI","text":"println(\"185.241.193.174:8088/proxy/\" + sc.applicationId + \"/jobs/\")\n","user":"DE_586_chernyak","dateUpdated":"2020-12-28T18:54:38+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":false,"results":{},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"185.241.193.174:8088/proxy/application_1607849830911_0172/jobs/\n"}]},"apps":[],"jobName":"paragraph_1608697987534_2084197304","id":"20201128-150602_756898802","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T20:43:34+0000","dateFinished":"2020-12-25T20:43:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3498"},{"text":"%md\n* Для джойна с таблицей `hw2.sample` было создано 195 tasks. Время выполнения 2 минуты.\n* Для джойна с таблицей `hw2.sample_big` было создано 397 tasks. Время выполнения - больше 10 минут. До конца так и не получилось дождаться - большая часть tasks фэйлится.\n* Посмотрел DAG-визуализацию","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:34:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<ul>\n<li>Для джойна с таблицей <code>hw2.sample</code> было создано 195 tasks. Время выполнения 2 минуты.</li>\n<li>Для джойна с таблицей <code>hw2.sample_big</code> было создано 397 tasks. Время выполнения хх минут.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1608922953023_237466916","id":"20201225-190233_654893370","dateCreated":"2020-12-25T19:02:33+0000","dateStarted":"2020-12-25T19:06:14+0000","dateFinished":"2020-12-25T19:06:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3499"},{"title":"Насильный broadcast","text":"%md\n\nОптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится ","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:41:39+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Оптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится</p>\n"}]},"apps":[],"jobName":"paragraph_1608697987535_927929130","id":"20201128-140749_375295552","dateCreated":"2020-12-23T04:33:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3500"},{"text":"%pyspark\n\nfrom pyspark.sql.functions import broadcast\n\nevents_full.join(broadcast(sample), \"event_id\").count()\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:02:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"104592\n"}]},"apps":[],"jobName":"paragraph_1608924666021_748871436","id":"20201225-193106_1781383785","dateCreated":"2020-12-25T19:31:06+0000","dateStarted":"2020-12-25T20:02:43+0000","dateFinished":"2020-12-25T20:04:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3501"},{"text":"%md\nджоин с насильным бродкастом с таблицей `sample_big` выпадает с ошибкой, проходит только с таблицей `sample`\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:06:13+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>джоин с насильным бродкастом с таблицей <code>sample_big</code> выпадает с ошибкой, проходит только с таблицей <code>sample</code></p>\n"}]},"apps":[],"jobName":"paragraph_1608926177601_-1431518094","id":"20201225-195617_1853836017","dateCreated":"2020-12-25T19:56:17+0000","dateStarted":"2020-12-25T20:06:13+0000","dateFinished":"2020-12-25T20:06:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3502"},{"title":"Отключение auto broadcast","text":"%md\nОтключить автоматический броадкаст командой `spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")`. Сделать джойн с семплом `hw2.sample`, сравнить время выполнения запроса.\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:43:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Отключить автоматический броадкаст командой <code>spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")</code>. Сделать джойн с семплом <code>hw2.sample</code>, сравнить время выполнения запроса.</p>\n"}]},"apps":[],"jobName":"paragraph_1608697987536_-541821039","id":"20201128-092252_410955057","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T19:43:59+0000","dateFinished":"2020-12-25T19:43:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3503"},{"text":"spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:52:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1608925445800_1936794756","id":"20201225-194405_557059779","dateCreated":"2020-12-25T19:44:05+0000","dateStarted":"2020-12-25T19:52:18+0000","dateFinished":"2020-12-25T19:52:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3504"},{"text":"%pyspark\n\nevents_full.join(sample, \"event_id\").count()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:52:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"104592\n"}]},"apps":[],"jobName":"paragraph_1608925529521_-319460577","id":"20201225-194529_362739728","dateCreated":"2020-12-25T19:45:29+0000","dateStarted":"2020-12-25T19:52:34+0000","dateFinished":"2020-12-25T19:54:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3505"},{"text":"%md\nПосле отключения автоматического броадкаста джоин с таблицей `hw22.sample` занял 2мин 22 сек - на 22 секунды больше\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:55:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>После отключения автоматического броадкаста джоин с таблицей <code>hw22.sample</code> занял 2мин 22 сек - на 22 секунды больше</p>\n"}]},"apps":[],"jobName":"paragraph_1608925962320_1156144337","id":"20201225-195242_1906650107","dateCreated":"2020-12-25T19:52:42+0000","dateStarted":"2020-12-25T19:55:16+0000","dateFinished":"2020-12-25T19:55:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3506"},{"title":"Вернуть настройку к исходной","text":"spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"26214400\")","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:55:29+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1608697987536_-710415496","id":"20201127-230625_1272901030","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T19:55:29+0000","dateFinished":"2020-12-25T19:55:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3507"},{"text":"spark.sql(\"clear cache\")","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:06:25+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res4: org.apache.spark.sql.DataFrame = []\n"}]},"apps":[],"jobName":"paragraph_1608697987537_-1834461759","id":"20201128-155645_947820002","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T20:06:25+0000","dateFinished":"2020-12-25T20:06:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3508"},{"title":"Задание 4","text":"%md\nВ процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.\n\nДатафрейм разделен на 30 партиций по ключу `city`, который имеет сильно  неравномерное распределение.","user":"DE_586_chernyak","dateUpdated":"2020-12-25T19:57:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>В процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.</p>\n<p>Датафрейм разделен на 30 партиций по ключу <code>city</code>, который имеет сильно  неравномерное распределение.</p>\n"}]},"apps":[],"jobName":"paragraph_1608697987537_-772997904","id":"20201128-163357_1545019956","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T19:57:51+0000","dateFinished":"2020-12-25T19:57:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3509"},{"text":"%pyspark \nfrom pyspark.sql.functions import col\n\nskew_df = spark.table(\"hw2.events_full\")\\\n.where(\"date = '2020-11-01'\")\\\n.repartition(30, col(\"city\"))\\\n.cache()\n\nskew_df.count()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:06:39+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true,"title":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"40000000\n"}]},"apps":[],"jobName":"paragraph_1608697987538_646005351","id":"20201128-162744_575252973","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T20:06:39+0000","dateFinished":"2020-12-25T20:09:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3510"},{"title":"4.1. Наблюдение проблемы","text":"%md\nПосчитать количество `event_count` различных событий `event_id` , содержащихся в `skew_df` с группировкой по городам. Результат упорядочить по `event_count`.\n\nВ spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют -- это и является проблемой, которую предлагается решить далее.","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:09:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Посчитать количество <code>event_count</code> различных событий <code>event_id</code> , содержащихся в <code>skew_df</code> с группировкой по городам. Результат упорядочить по <code>event_count</code>.</p>\n<p>В spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют &ndash; это и является проблемой, которую предлагается решить далее.</p>\n"}]},"apps":[],"jobName":"paragraph_1608697987539_-796444927","id":"20201128-164139_1371291032","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T20:09:03+0000","dateFinished":"2020-12-25T20:09:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3511"},{"text":"%pyspark\n\nskew_df.show()\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:22:24+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+-------------+--------------------+----------+\n|            event_id|         city|            skew_key|      date|\n+--------------------+-------------+--------------------+----------+\n|f729fb12f3c864d35...|SMALL_CITY_40|f729fb12f3c864d35...|2020-11-01|\n|e2a9a6132ed63b7ac...|SMALL_CITY_40|e2a9a6132ed63b7ac...|2020-11-01|\n|aa15104b3bc9301fb...|SMALL_CITY_40|aa15104b3bc9301fb...|2020-11-01|\n|ba0b0ef54600130f6...|SMALL_CITY_40|ba0b0ef54600130f6...|2020-11-01|\n|c0393d198d655c0ea...|SMALL_CITY_66|c0393d198d655c0ea...|2020-11-01|\n|d7aa3dae05b4a8ddb...|SMALL_CITY_40|d7aa3dae05b4a8ddb...|2020-11-01|\n|56654782e52f598ce...|SMALL_CITY_66|56654782e52f598ce...|2020-11-01|\n|c9f14144fa9b4fef8...|SMALL_CITY_40|c9f14144fa9b4fef8...|2020-11-01|\n|22bde9930551ea754...|SMALL_CITY_66|22bde9930551ea754...|2020-11-01|\n|9eace23b1377dcbaa...|SMALL_CITY_66|9eace23b1377dcbaa...|2020-11-01|\n|58424405d696031a8...|SMALL_CITY_40|58424405d696031a8...|2020-11-01|\n|d1ef798262289b351...|SMALL_CITY_40|d1ef798262289b351...|2020-11-01|\n|057803683b05f35a5...|SMALL_CITY_40|057803683b05f35a5...|2020-11-01|\n|9af732de6701ce5d4...|SMALL_CITY_40|9af732de6701ce5d4...|2020-11-01|\n|3239c2353c3fdebda...|SMALL_CITY_40|3239c2353c3fdebda...|2020-11-01|\n|1b80326b78af437fb...|SMALL_CITY_66|1b80326b78af437fb...|2020-11-01|\n|7c7685b2aa78ceb8c...|SMALL_CITY_40|7c7685b2aa78ceb8c...|2020-11-01|\n|388dc838d96cd9316...|SMALL_CITY_40|388dc838d96cd9316...|2020-11-01|\n|7022db21149e35b8a...|SMALL_CITY_40|7022db21149e35b8a...|2020-11-01|\n|56c949e85f57aa294...|SMALL_CITY_40|56c949e85f57aa294...|2020-11-01|\n+--------------------+-------------+--------------------+----------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1608927725849_-260097041","id":"20201225-202205_1328808393","dateCreated":"2020-12-25T20:22:05+0000","dateStarted":"2020-12-25T20:22:24+0000","dateFinished":"2020-12-25T20:22:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3512"},{"text":"%pyspark\n\nskew_df\\\n    .groupBy(\"city\")\\\n    .count()\\\n    .orderBy(col(\"count\"))\\\n    .show()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:39:41+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+-----+\n|          city|count|\n+--------------+-----+\n|  SMALL_CITY_0|19762|\n|SMALL_CITY_100|20121|\n| SMALL_CITY_10|39613|\n| SMALL_CITY_19|39653|\n| SMALL_CITY_68|39669|\n| SMALL_CITY_27|39678|\n| SMALL_CITY_97|39704|\n| SMALL_CITY_40|39709|\n| SMALL_CITY_65|39735|\n| SMALL_CITY_78|39741|\n| SMALL_CITY_77|39757|\n| SMALL_CITY_44|39759|\n| SMALL_CITY_52|39767|\n| SMALL_CITY_99|39772|\n| SMALL_CITY_73|39773|\n| SMALL_CITY_37|39775|\n| SMALL_CITY_83|39802|\n| SMALL_CITY_70|39804|\n| SMALL_CITY_29|39808|\n|  SMALL_CITY_2|39814|\n+--------------+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1608926909293_1795696442","id":"20201225-200829_2139911540","dateCreated":"2020-12-25T20:08:29+0000","dateStarted":"2020-12-25T20:39:41+0000","dateFinished":"2020-12-25T20:42:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3513"},{"text":"println(\"185.241.193.174:8088/proxy/\" + sc.applicationId + \"/jobs/\")","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:59:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"185.241.193.174:8088/proxy/application_1607849830911_0172/jobs/\n"}]},"apps":[],"jobName":"paragraph_1608929226010_990226049","id":"20201225-204706_417166754","dateCreated":"2020-12-25T20:47:06+0000","dateStarted":"2020-12-25T20:59:33+0000","dateFinished":"2020-12-25T20:59:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3514"},{"text":"%md\nЗашел в Details for Stage 51, открыл Event Timeline и действительно увидел, что у Task 27 время выполнения 2,9 минут, в то время как у остальных Tasks не превышает 2 секунд. \n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:50:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Зашел в Details for Stage 51, открыл Event Timeline и действительно увидел, что у Task 27 время выполнения 2,9 минут, в то время как у остальных Tasks не превышает 2 секунд.</p>\n"}]},"apps":[],"jobName":"paragraph_1608929225096_1068839962","id":"20201225-204705_242201835","dateCreated":"2020-12-25T20:47:05+0000","dateStarted":"2020-12-25T20:50:49+0000","dateFinished":"2020-12-25T20:50:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3515"},{"title":"4.2. repartition","text":"%md\nодин из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num -- количество партиций, на которые будет перемешан исходный датафрейм","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:51:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>один из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num &ndash; количество партиций, на которые будет перемешан исходный датафрейм</p>\n"}]},"apps":[],"jobName":"paragraph_1608697987539_-80425508","id":"20201128-164814_1641460265","dateCreated":"2020-12-23T04:33:07+0000","dateStarted":"2020-12-25T20:51:17+0000","dateFinished":"2020-12-25T20:51:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3516"},{"text":"%pyspark\n\nskew_df_r = skew_df.repartition(30).cache()","user":"DE_586_chernyak","dateUpdated":"2020-12-25T20:52:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1608928935640_-1569435011","id":"20201225-204215_63031380","dateCreated":"2020-12-25T20:42:15+0000","dateStarted":"2020-12-25T20:52:42+0000","dateFinished":"2020-12-25T20:52:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3517"},{"text":"%pyspark\n\nskew_df_r\\\n    .groupBy(\"city\")\\\n    .count()\\\n    .orderBy(col(\"count\"))\\\n    .show()\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T21:05:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------+-----+\n|          city|count|\n+--------------+-----+\n|  SMALL_CITY_0|19762|\n|SMALL_CITY_100|20121|\n| SMALL_CITY_10|39613|\n| SMALL_CITY_19|39653|\n| SMALL_CITY_68|39669|\n| SMALL_CITY_27|39678|\n| SMALL_CITY_97|39704|\n| SMALL_CITY_40|39709|\n| SMALL_CITY_65|39735|\n| SMALL_CITY_78|39741|\n| SMALL_CITY_77|39757|\n| SMALL_CITY_44|39759|\n| SMALL_CITY_52|39767|\n| SMALL_CITY_99|39772|\n| SMALL_CITY_73|39773|\n| SMALL_CITY_37|39775|\n| SMALL_CITY_83|39802|\n| SMALL_CITY_70|39804|\n| SMALL_CITY_29|39808|\n|  SMALL_CITY_2|39814|\n+--------------+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1608928933407_205512957","id":"20201225-204213_1739930941","dateCreated":"2020-12-25T20:42:13+0000","dateStarted":"2020-12-25T21:05:48+0000","dateFinished":"2020-12-25T21:06:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3518"},{"text":"%md\nпосле перемешивания время распределилось более равномерно","user":"DE_586_chernyak","dateUpdated":"2020-12-25T21:08:08+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>после перемешивания время распределилось более равномерно</p>\n"}]},"apps":[],"jobName":"paragraph_1608930316257_-583728207","id":"20201225-210516_1008371549","dateCreated":"2020-12-25T21:05:16+0000","dateStarted":"2020-12-25T21:08:08+0000","dateFinished":"2020-12-25T21:08:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3519"},{"title":"4.3. Key Salting","text":"%md\n.\n.\n.\nДругой способ исправить неравномерность по ключу -- создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city='BIG_CITY', которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand -- случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным. \n\nТакая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8\n\nЧто нужно реализовать:\n* добавить синтетический ключ\n* группировка по синтетическому ключу\n* восстановление исходного значения\n* группировка по исходной колонке","user":"DE_586_chernyak","dateUpdated":"2020-12-23T04:33:07+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>.\n<br  />.\n<br  />.\n<br  />Другой способ исправить неравномерность по ключу &ndash; создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city='BIG_CITY', которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand &ndash; случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным.</p>\n<p>Такая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8</p>\n<p>Что нужно реализовать:</p>\n<ul>\n<li>добавить синтетический ключ</li>\n<li>группировка по синтетическому ключу</li>\n<li>восстановление исходного значения</li>\n<li>группировка по исходной колонке</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1608697987540_1460948065","id":"20201128-173534_1924644474","dateCreated":"2020-12-23T04:33:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3520"},{"text":"%md\n\nпока не очень разобрался в этом задании\n","user":"DE_586_chernyak","dateUpdated":"2020-12-25T21:12:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>пока не очень разобрался в этом задании</p>\n"}]},"apps":[],"jobName":"paragraph_1608930562305_-113003533","id":"20201225-210922_990608819","dateCreated":"2020-12-25T21:09:22+0000","dateStarted":"2020-12-25T21:12:31+0000","dateFinished":"2020-12-25T21:12:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3521"},{"text":"spark.stop","user":"DE_586_chernyak","dateUpdated":"2020-12-23T04:33:07+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1608697987541_641853193","id":"20201128-174934_1428813475","dateCreated":"2020-12-23T04:33:07+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3522"}],"name":"DE_586_chernyak/lesson02","id":"2FW2UK1Y2","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}